{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "nb-title",
   "metadata": {},
   "source": [
    "# ImmuneMethylTools — Validation Notebook\n",
    "## Data Cleaning to Discovery: A Step-by-Step Walkthrough\n",
    "\n",
    "---\n",
    "\n",
    "Purpose: This notebook is the analyst's guided tour of the ImmuneMethylTools pipeline. Each step exposes a real pitfall in B-cell/T-cell DNA methylation analysis, applies a targeted fix from the `core/` library, and shows exactly what changes.\n",
    "\n",
    "Design rule: All detection logic, thresholds, and statistical tests are imported from `core/`. Notebook cells contain only data access, display calls, and matplotlib/seaborn visualization.\n",
    "\n",
    "| Step | Focus | Key Artifact Addressed |\n",
    "|------|-------|------------------------|\n",
    "| 0    | Raw EDA          | All 6 stumper artifacts; batch confound |\n",
    "| 1    | Identity & Integrity | Sex metadata mixup; technical duplicates |\n",
    "| 2    | Surgical Strike  | Clonal VDJ amplification artifact |\n",
    "| 3    | Harmonization    | Batch × disease confound |\n",
    "| 4    | Scientific Discovery | True biological DMR signal |\n",
    "| 5    | ML Validation    | Honest vs. inflated AUC |\n",
    "| 6    | PDF Report       | Full pipeline run → shareable PDF |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b497899c-30aa-4bde-bdf6-25c541af5d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "sys.path.insert(0, os.path.abspath('..'))\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # quiet minor issues\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from IPython.display import display\n",
    "\n",
    "# ── Core module imports (all logic lives here) ──────────────────────────────\n",
    "from core.infrastructure.io_utils import data_path, load_methylation\n",
    "from core.infrastructure.visuals import compute_pca_coords, compute_sample_qc_stats\n",
    "from core.qc.qc_guard import audit_quality, detect_contamination, filter_site_quality\n",
    "from core.qc.xci_guard import compute_xci_signal, detect_sex_mixups\n",
    "from core.qc.sample_audit import detect_duplicates\n",
    "from core.analytics.normalizer import check_confounding, check_continuous_confound, robust_normalize\n",
    "from core.qc.repertoire_clonality import flag_clonal_artifacts, mask_clonal_vdj_sites\n",
    "from core.analytics.dmr_hunter import find_dmrs\n",
    "from core.analytics.ml_guard import run_safe_model\n",
    "\n",
    "%matplotlib inline \n",
    "plt.rcParams.update({\n",
    "    'figure.dpi': 120,\n",
    "    'font.size': 11,\n",
    "    'axes.spines.top': False,\n",
    "    'axes.spines.right': False,\n",
    "})\n",
    "\n",
    "# Shared palettes\n",
    "DISEASE_PAL  = {'Case': '#E05C5C', 'Control': '#4A90D9'}\n",
    "BATCH_PAL    = {'Batch_01': '#F5A623', 'Batch_02': '#7ED321', 'Batch_03': '#9B59B6'}\n",
    "SEX_PAL      = {'M': '#3498DB', 'F': '#E91E63'}\n",
    "\n",
    "print('All core modules loaded. Ready to begin the walkthrough.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step0-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 0: The \"Broken\" Data — Raw Exploratory Data Analysis\n",
    "\n",
    "We load `mock_methylation.csv` without any filtering. The raw data contains seven deliberately injected artifacts plus a true biological signal. Our job is to find and fix each one before calling a single DMR.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step0-load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Load raw data ──────────────────────────────────────────────────────────\n",
    "CSV_PATH = data_path('mock_methylation.csv')\n",
    "df_raw   = load_methylation(CSV_PATH, verbose=False)\n",
    "\n",
    "n_samples  = df_raw['sample_id'].nunique()\n",
    "n_cpgs     = df_raw['cpg_id'].nunique()\n",
    "\n",
    "print(f'Shape        : {len(df_raw):,} rows  x  {len(df_raw.columns)} columns')\n",
    "print(f'Samples      : {n_samples}')\n",
    "print(f'CpG sites    : {n_cpgs:,}')\n",
    "print(f'Columns      : {list(df_raw.columns)}')\n",
    "print()\n",
    "\n",
    "meta = df_raw.drop_duplicates('sample_id')[['sample_id', 'patient_id', 'batch_id', 'disease_label', 'sex']]\n",
    "print('Disease breakdown:')\n",
    "print(meta['disease_label'].value_counts().to_string())\n",
    "print()\n",
    "print('Batch breakdown:')\n",
    "print(meta['batch_id'].value_counts().to_string())\n",
    "print()\n",
    "print('First 5 rows (long format — all 16 columns):')\n",
    "display(df_raw.head())\n",
    "\n",
    "# ── New columns: GRCh38 coordinates and GC content ─────────────────────────\n",
    "print()\n",
    "print('GRCh38 coordinate columns (chrom, pos) — non-X autosomal example:')\n",
    "autosomal_sample = df_raw[~df_raw['is_x_chromosome']].head(3)[['cpg_id', 'chrom', 'pos', 'gc_content', 'is_vdj_region']]\n",
    "display(autosomal_sample)\n",
    "\n",
    "print('Chromosome distribution (unique CpGs):')\n",
    "chrom_counts = c['chrom'].value_counts().sort_index()\n",
    "print(chrom_counts.to_string())\n",
    "print(f\"\\ngc_content range: [{df_raw['gc_content'].min():.2f}, {df_raw['gc_content'].max():.2f}]  \"\n",
    "      f\"(constant per CpG across samples — negative control for GC bias)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step0-v1-header",
   "metadata": {},
   "source": [
    "### Visual 1 — Six Lab and Sample Artifacts\n",
    "\n",
    "Each panel exposes one artifact visible in the raw data. These are exactly the patterns that would mislead a naive pipeline into reporting false positives.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step0-artifacts",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Precompute per-sample stats and XCI signal ──────────────────────────────\n",
    "sample_stats = compute_sample_qc_stats(df_raw)\n",
    "\n",
    "# XCI signal from core module\n",
    "xci_signal = compute_xci_signal(df_raw)\n",
    "sex_flagged_ids, _ = detect_sex_mixups(df_raw)\n",
    "xci_signal['mismatch'] = xci_signal['sample_id'].isin(sex_flagged_ids)\n",
    "xci_signal = xci_signal.reset_index(drop=True)\n",
    "\n",
    "# VDJ rows\n",
    "vdj_df  = df_raw[df_raw['is_vdj_region']].copy()\n",
    "nvdj_df = df_raw[~df_raw['is_vdj_region']].sample(600, random_state=42)\n",
    "\n",
    "# Duplicate pair\n",
    "s010 = df_raw[df_raw['sample_id'] == 'S010'][['cpg_id', 'beta_value']].rename(columns={'beta_value': 'S010'})\n",
    "sdup = df_raw[df_raw['sample_id'] == 'S_DUP'][['cpg_id', 'beta_value']].rename(columns={'beta_value': 'S_DUP'})\n",
    "dup_merged = s010.merge(sdup, on='cpg_id')\n",
    "\n",
    "# ── 6-panel figure ─────────────────────────────────────────────────────────\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('The Six Stumper Artifacts — Raw Data', fontsize=14, fontweight='bold', y=1.01)\n",
    "\n",
    "x_idx = range(len(sample_stats))\n",
    "\n",
    "# ── Panel 1: Bisulfite Conversion Failure ──────────────────────────────────\n",
    "ax = axes[0, 0]\n",
    "colors_bs = ['#E05C5C' if r > 0.02 else '#4A90D9' for r in sample_stats['mean_ncpg_rate']]\n",
    "ax.bar(x_idx, sample_stats['mean_ncpg_rate'], color=colors_bs, alpha=0.85, edgecolor='white', linewidth=0.4)\n",
    "ax.axhline(0.02, color='red', linestyle='--', linewidth=1.5, label='Fail threshold (2%)')\n",
    "n_bs_fail = (sample_stats['mean_ncpg_rate'] > 0.02).sum()\n",
    "ax.text(0.97, 0.95, f'{n_bs_fail} samples failed', transform=ax.transAxes,\n",
    "        ha='right', va='top', color='#E05C5C', fontsize=10, fontweight='bold')\n",
    "ax.set_xlabel('Sample index')\n",
    "ax.set_ylabel('Mean non-CpG meth. rate')\n",
    "ax.set_title('Artifact 1 — Bisulfite Conversion\\nFailure (non-CpG rate > 2%)', fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "# ── Panel 2: Contamination — bimodal KDE ──────────────────────────────────\n",
    "ax = axes[0, 1]\n",
    "beta_contaminated = df_raw[df_raw['sample_id'] == 'S020']['beta_value']\n",
    "beta_normal       = df_raw[df_raw['sample_id'] == 'S005']['beta_value']\n",
    "beta_contaminated.plot.kde(ax=ax, color='#E05C5C', linewidth=2.5, label='S020 (contaminated)')\n",
    "beta_normal.plot.kde(ax=ax, color='#4A90D9', linewidth=2.5, label='S005 (normal)')\n",
    "ax.axvspan(0.35, 0.65, alpha=0.12, color='orange', label='Bimodal \"muddy\" zone')\n",
    "ax.set_xlabel('Beta value')\n",
    "ax.set_ylabel('Density')\n",
    "ax.set_title('Artifact 2 — Sample Contamination\\n\"Muddy\" bimodal beta distribution', fontweight='bold')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# ── Panel 3: Low Coverage ──────────────────────────────────────────────────\n",
    "ax = axes[0, 2]\n",
    "colors_dep = ['#E05C5C' if d < 10 else '#4A90D9' for d in sample_stats['mean_depth']]\n",
    "ax.bar(x_idx, sample_stats['mean_depth'], color=colors_dep, alpha=0.85, edgecolor='white', linewidth=0.4)\n",
    "ax.axhline(10, color='red', linestyle='--', linewidth=1.5, label='Depth threshold (10x)')\n",
    "n_dep_fail = (sample_stats['mean_depth'] < 10).sum()\n",
    "ax.text(0.97, 0.95, f'{n_dep_fail} samples below threshold',\n",
    "        transform=ax.transAxes, ha='right', va='top', color='#E05C5C', fontsize=9, fontweight='bold')\n",
    "ax.set_xlabel('Sample index')\n",
    "ax.set_ylabel('Mean read depth (x)')\n",
    "ax.set_title('Artifact 3 — Low Coverage\\nMean depth < 10x fails QC', fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "# ── Panel 4: Clonal VDJ Artifact ──────────────────────────────────────────\n",
    "ax = axes[1, 0]\n",
    "ax.scatter(nvdj_df['fragment_length'], nvdj_df['beta_value'],\n",
    "           alpha=0.15, s=8, color='#AAAAAA', label='Non-VDJ sites (sample)')\n",
    "ax.scatter(vdj_df['fragment_length'], vdj_df['beta_value'],\n",
    "           alpha=0.55, s=14, color='#E05C5C', label='VDJ sites')\n",
    "ax.axhline(0.80, color='#8B0000', linestyle='--', linewidth=1.2, alpha=0.8)\n",
    "ax.axvline(180,  color='#8B0000', linestyle='--', linewidth=1.2, alpha=0.8)\n",
    "ax.text(183, 0.82, 'Clonal zone\\n(beta>0.8, frag>180bp)', color='#8B0000', fontsize=8)\n",
    "ax.set_xlabel('Fragment length (bp)')\n",
    "ax.set_ylabel('Beta value')\n",
    "ax.set_title('Artifact 4 — Clonal VDJ Artifact\\n\"Fake Biomarker\": high beta + long fragment', fontweight='bold')\n",
    "ax.legend(fontsize=8)\n",
    "\n",
    "# ── Panel 5: Sex Metadata Mixup ────────────────────────────────────────────\n",
    "ax = axes[1, 1]\n",
    "for sex_label in ['M', 'F']:\n",
    "    grp = xci_signal[xci_signal['sex'] == sex_label]\n",
    "    ax.scatter(grp.index, grp['mean_x_beta'],\n",
    "               color=SEX_PAL[sex_label], alpha=0.65, s=40, zorder=2,\n",
    "               label=f'Reported {sex_label}')\n",
    "mismatched = xci_signal[xci_signal['mismatch']]\n",
    "ax.scatter(mismatched.index, mismatched['mean_x_beta'],\n",
    "           s=150, marker='x', color='red', zorder=5, linewidths=2.5,\n",
    "           label=f'Mismatch flagged (n={len(mismatched)})')\n",
    "ax.axhspan(0.40, 0.65, alpha=0.08, color='#E91E63', label='Expected female range')\n",
    "ax.axhspan(0.00, 0.35, alpha=0.08, color='#3498DB', label='Expected male range')\n",
    "ax.set_xlabel('Sample index (all samples)')\n",
    "ax.set_ylabel('Mean X-chromosome beta')\n",
    "ax.set_title('Artifact 5 — Sex Metadata Mixup\\nX-linked methylation contradicts reported sex', fontweight='bold')\n",
    "ax.legend(fontsize=7, ncol=2)\n",
    "\n",
    "# ── Panel 6: Technical Duplicate ──────────────────────────────────────────\n",
    "ax = axes[1, 2]\n",
    "sample_pts = dup_merged.sample(min(500, len(dup_merged)), random_state=42)\n",
    "ax.scatter(sample_pts['S010'], sample_pts['S_DUP'], alpha=0.4, s=10, color='#9B59B6')\n",
    "r_val = dup_merged[['S010', 'S_DUP']].corr().iloc[0, 1]\n",
    "ax.plot([0, 1], [0, 1], 'r--', linewidth=1.5, label=f'Identity line (r = {r_val:.4f})')\n",
    "ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n",
    "ax.set_xlabel('S010 beta value')\n",
    "ax.set_ylabel('S_DUP beta value')\n",
    "ax.set_title(f'Artifact 6 — Technical Duplicate\\nS010 vs S_DUP  (Pearson r = {r_val:.4f})', fontweight='bold')\n",
    "ax.legend(fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4gpkjlkydv1",
   "metadata": {},
   "source": [
    "\n",
    "### M-bias — Read-Level Bisulfite Conversion QC (Educational Aside)\n",
    "\n",
    "The six-panel figure above flags samples by their **whole-sample** non-CpG methylation rate (Panel A). That per-sample aggregate is the project's bisulfite QC metric. Behind that number lies a positional pattern that pre-processing tools diagnose at the raw-read level: the **M-bias plot**.\n",
    "\n",
    "   * What it is: A technical artifact from inefficient bisulfite conversion, causing artificially high methylation at the ends of sequencing reads.\n",
    "   * How to diagnose: An \"M-bias plot\" reveals a \"smile\" pattern of inflated non-CpG (CHH) methylation in the first and last ~10 base pairs.\n",
    "   * How to fix: Trim the biased read ends before alignment using a tool like Trim Galore.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1cvt277p9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ── Educational M-bias simulation — CHH context ────────────────────────────\n",
    "# Illustrates what Bismark's bismark2summary would show for two virtual\n",
    "# samples: a clean library (uniform low CHH methylation) and a biased library\n",
    "# (elevated CHH rate at read ends from incomplete bisulfite conversion).\n",
    "# Real M-bias plots are computed from per-read CHH pileups before alignment;\n",
    "# the simulation here uses binomial draws at each read position.\n",
    "\n",
    "import os\n",
    "\n",
    "rng         = np.random.default_rng(seed=42)\n",
    "READ_LENGTH = 150\n",
    "N_READS     = 2_000\n",
    "END_ZONE    = 10      # bp from each end where conversion is less efficient\n",
    "MID_RATE    = 0.015   # ~1.5% CHH baseline (complete conversion)\n",
    "END_RATE    = 0.060   # ~6% CHH at ends (incomplete conversion)\n",
    "\n",
    "def _chh_profile(n_reads, read_length, end_rate, mid_rate, end_zone, rng):\n",
    "    \"\"\"Return mean CHH methylation rate per position across n_reads.\"\"\"\n",
    "    prob = np.full((n_reads, read_length), mid_rate)\n",
    "    prob[:, :end_zone]               = end_rate   # 5' end\n",
    "    prob[:, read_length - end_zone:] = end_rate   # 3' end\n",
    "    return rng.binomial(1, prob).mean(axis=0)\n",
    "\n",
    "clean_profile  = _chh_profile(N_READS, READ_LENGTH, MID_RATE, MID_RATE, END_ZONE, rng)\n",
    "biased_profile = _chh_profile(N_READS, READ_LENGTH, END_RATE, MID_RATE, END_ZONE, rng)\n",
    "\n",
    "positions = np.arange(READ_LENGTH)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(11, 4))\n",
    "ax.plot(positions, clean_profile  * 100, color='#4A90D9', linewidth=2,\n",
    "        label='Clean library  (uniform conversion, CHH ~1.5%)')\n",
    "ax.plot(positions, biased_profile * 100, color='#E05C5C', linewidth=2,\n",
    "        label='Biased library  (end-zone conversion failure, CHH ~6%)')\n",
    "\n",
    "ax.axvspan(0,                      END_ZONE - 1,         alpha=0.10, color='red')\n",
    "ax.axvspan(READ_LENGTH - END_ZONE, READ_LENGTH - 1,      alpha=0.10, color='red',\n",
    "           label=f'End zone (first/last {END_ZONE} bp) — trim before alignment')\n",
    "ax.axhline(2.0, color='gray', linestyle='--', linewidth=1.0,\n",
    "           label=\"2% whole-sample non-CpG threshold (this project's QC metric)\")\n",
    "\n",
    "ax.set_xlabel('Position within read (bp)', fontsize=11)\n",
    "ax.set_ylabel('CHH methylation rate (%)', fontsize=11)\n",
    "ax.set_title(\n",
    "    'M-bias Plot — CHH Context  (2,000 simulated reads per sample)\\n'\n",
    "    'End-zone CHH spikes indicate incomplete bisulfite conversion; clip those positions before alignment',\n",
    "    fontweight='bold',\n",
    ")\n",
    "ax.set_xlim(0, READ_LENGTH - 1)\n",
    "ax.set_ylim(0, 10)\n",
    "ax.legend(fontsize=9, loc='upper center')\n",
    "plt.tight_layout()\n",
    "\n",
    "figures_dir = os.path.join('..', 'output', 'figures')\n",
    "os.makedirs(figures_dir, exist_ok=True)\n",
    "out_path = os.path.join(figures_dir, 'mbias_educational.png')\n",
    "fig.savefig(out_path, dpi=150, bbox_inches='tight')\n",
    "print(f'Saved: {out_path}')\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('Interpretation:')\n",
    "print(f'  Clean library  : CHH rate is flat ~1.5% across all {READ_LENGTH} positions.')\n",
    "print(f'  Biased library : CHH rate spikes to ~6% in the first and last {END_ZONE} bp.')\n",
    "print(f'  Fix            : hard-clip {END_ZONE} bp from both read ends before alignment.')\n",
    "print()\n",
    "print(\"Link to this project's QC:\")\n",
    "print('  non_cpg_meth_rate is the whole-sample CHH/CHG aggregate. S001 and S002 exceed')\n",
    "print('  the 2% threshold because their end-zone inflation is severe enough to push the')\n",
    "print('  sample mean over the limit. The M-bias plot is the positional view behind that number.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step0-v2-header",
   "metadata": {},
   "source": [
    "### Visual 2 — The Batch Confound: Why a Naive Analysis Fails\n",
    "\n",
    "PCA on the raw data reveals that samples cluster by sequencing batch rather than by disease label. `Batch_01` was enriched with Case samples during experiment setup, so any naive differential methylation test would report batch-driven differences as biological signal.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step0-pca-batch",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_raw, var_raw = compute_pca_coords(df_raw, value_col='beta_value')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 6))\n",
    "fig.suptitle('PCA on Raw Data — The Batch Confound', fontsize=13, fontweight='bold')\n",
    "\n",
    "# Left: color by batch\n",
    "ax = axes[0]\n",
    "for batch, grp in pca_raw.groupby('batch_id'):\n",
    "    ax.scatter(grp['PC1'], grp['PC2'], label=batch,\n",
    "               color=BATCH_PAL.get(batch, 'gray'), alpha=0.85, s=70, edgecolors='white', linewidths=0.5)\n",
    "ax.set_xlabel(f'PC1 ({var_raw[0]:.1%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({var_raw[1]:.1%} variance)')\n",
    "ax.set_title('Colored by Batch\\nSamples cluster by plate, not biology')\n",
    "ax.legend(title='Batch', fontsize=9)\n",
    "\n",
    "# Right: color by disease — clusters don't match\n",
    "ax = axes[1]\n",
    "for disease, grp in pca_raw.groupby('disease_label'):\n",
    "    ax.scatter(grp['PC1'], grp['PC2'], label=disease,\n",
    "               color=DISEASE_PAL.get(disease, 'gray'), alpha=0.85, s=70, edgecolors='white', linewidths=0.5)\n",
    "ax.set_xlabel(f'PC1 ({var_raw[0]:.1%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({var_raw[1]:.1%} variance)')\n",
    "ax.set_title('Colored by Disease Label\\nDisease clusters don\\'t align with variance')\n",
    "ax.legend(title='Disease', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Conclusion: The first principal component separates batches, not cases from controls.')\n",
    "print('A naive analyst would discover Batch_01 enrichment as a \"disease signal\". We must fix this.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 1: Identity & Integrity — Sex Check and Duplicate Guard\n",
    "\n",
    "Before any biological analysis, we verify that each sample is who it claims to be: correct sex metadata and a unique individual. The `xci_guard` and `sample_audit` modules handle this automatically.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1a-header",
   "metadata": {},
   "source": [
    "### 1a — XCI Sex Guard: The Lab-Swap Check\n",
    "\n",
    "In females (XX), one X chromosome is silenced (X-Chromosome Inactivation, XCI), producing a characteristic mean X-linked methylation of roughly 0.5. Males (XY) show low X methylation roughly (0.25). A mismatch between reported sex and observed X-linked signal reveals a sample swap or metadata error — which could be a case/control label flip in disguise.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1a-sex",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Run the XCI guard ──────────────────────────────────────────────────────\n",
    "# Note: the pipeline runs this after Stage 1a+1b QC, but we demo on raw data\n",
    "# to show the signal is detectable even before sample-level QC.\n",
    "sex_flagged_ids, sex_report = detect_sex_mixups(df_raw)\n",
    "xci_full = compute_xci_signal(df_raw)\n",
    "xci_full = xci_full.merge(\n",
    "    sex_report[['sample_id', 'xci_mismatch']], on='sample_id', how='left'\n",
    ")\n",
    "\n",
    "print(f'Samples with sex-signal mismatch: {len(sex_flagged_ids)}')\n",
    "print(f'  Flagged sample IDs: {sex_flagged_ids}')\n",
    "print()\n",
    "print('XCI report for flagged samples:')\n",
    "display(sex_report[sex_report['sample_id'].isin(sex_flagged_ids)]\n",
    "        [['sample_id', 'sex', 'mean_x_beta', 'n_x_cpgs', 'xci_mismatch']])\n",
    "\n",
    "# ── Plot: Mean X-chromosome beta by reported sex ───────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(9, 5))\n",
    "\n",
    "# Background shading for expected ranges\n",
    "ax.axhspan(0.40, 0.65, alpha=0.10, color='#E91E63', label='Expected female range [0.40, 0.65]')\n",
    "ax.axhspan(0.00, 0.35, alpha=0.10, color='#3498DB', label='Expected male range [0.00, 0.35]')\n",
    "\n",
    "# Points colored by reported sex\n",
    "for sex_label in ['M', 'F']:\n",
    "    grp = xci_full[xci_full['sex'] == sex_label]\n",
    "    ax.scatter(grp.index, grp['mean_x_beta'], color=SEX_PAL[sex_label],\n",
    "               s=60, alpha=0.75, zorder=3, label=f'Reported {sex_label}')\n",
    "    for _, row in grp.iterrows():\n",
    "        ax.annotate(row['sample_id'], (row.name, row['mean_x_beta']),\n",
    "                    textcoords='offset points', xytext=(3, 2), fontsize=5, alpha=0.5)\n",
    "\n",
    "# Highlight mismatches\n",
    "flagged_xci = xci_full[xci_full['sample_id'].isin(sex_flagged_ids)]\n",
    "ax.scatter(flagged_xci.index, flagged_xci['mean_x_beta'],\n",
    "           s=200, marker='X', color='red', zorder=6, linewidths=0,\n",
    "           label='MISMATCH — flagged for removal')\n",
    "\n",
    "ax.set_xlabel('Sample index', fontsize=11)\n",
    "ax.set_ylabel('Mean X-chromosome beta value', fontsize=11)\n",
    "ax.set_title(\n",
    "    'XCI Sex Guard — Reported vs. Observed Sex Signal\\n'\n",
    "    'Samples outside their expected range are lab swaps or metadata errors',\n",
    "    fontweight='bold'\n",
    ")\n",
    "ax.legend(fontsize=8, loc='upper right')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print('Interpretation:')\n",
    "for sid in sex_flagged_ids:\n",
    "    row = sex_report.set_index('sample_id').loc[sid]\n",
    "    print(f'  {sid}: reported sex={row[\"sex\"]}, mean_x_beta={row[\"mean_x_beta\"]:.3f}  '\n",
    "          f'-> signal inconsistent with reported sex -> REMOVED')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1b-header",
   "metadata": {},
   "source": [
    "### 1b — Technical Duplicate Detection\n",
    "\n",
    "Using pairwise Pearson correlation across the top 100 most variable CpGs, `sample_audit` identifies samples that are suspiciously identical. A pair with r > 0.99 is almost certainly the same library sequenced twice — keeping both would double-count one individual.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1b-dedup",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Run duplicate detection on post-QC data ────────────────────────────────\n",
    "# To mirror the pipeline, run dedup after Stage 1a+1b+1c QC.\n",
    "qc_pass     = audit_quality(df_raw)\n",
    "contaminated, _ = detect_contamination(df_raw)\n",
    "after_1ab   = [s for s in qc_pass if s not in contaminated]\n",
    "df_1ab      = df_raw[df_raw['sample_id'].isin(after_1ab)].copy()\n",
    "after_1abc  = [s for s in after_1ab if s not in sex_flagged_ids]\n",
    "df_1abc     = df_raw[df_raw['sample_id'].isin(after_1abc)].copy()\n",
    "\n",
    "dup_pairs, dups_to_drop = detect_duplicates(df_1abc)\n",
    "flagged_pairs = dup_pairs[dup_pairs['duplicate_flag']]\n",
    "\n",
    "print(f'Duplicate pairs detected: {len(flagged_pairs)}')\n",
    "print(f'Samples to drop         : {dups_to_drop}')\n",
    "print()\n",
    "display(flagged_pairs[['sample_a', 'sample_b', 'pearson_r', 'duplicate_flag']])\n",
    "\n",
    "# ── Correlation scatter for the flagged pair ───────────────────────────────\n",
    "if len(flagged_pairs) > 0:\n",
    "    pair = flagged_pairs.iloc[0]\n",
    "    sid_a, sid_b = pair['sample_a'], pair['sample_b']\n",
    "\n",
    "    beta_a = df_raw[df_raw['sample_id'] == sid_a][['cpg_id', 'beta_value']].rename(columns={'beta_value': sid_a})\n",
    "    beta_b = df_raw[df_raw['sample_id'] == sid_b][['cpg_id', 'beta_value']].rename(columns={'beta_value': sid_b})\n",
    "    merged = beta_a.merge(beta_b, on='cpg_id').sample(min(800, len(beta_a)), random_state=42)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    ax.scatter(merged[sid_a], merged[sid_b], alpha=0.3, s=10, color='#9B59B6')\n",
    "    ax.plot([0, 1], [0, 1], 'r--', linewidth=1.8, label=f'Identity line  (r = {pair[\"pearson_r\"]:.6f})')\n",
    "    ax.set_xlim(0, 1); ax.set_ylim(0, 1)\n",
    "    ax.set_xlabel(f'{sid_a} beta value', fontsize=11)\n",
    "    ax.set_ylabel(f'{sid_b} beta value', fontsize=11)\n",
    "    ax.set_title(\n",
    "        f'Technical Duplicate: {sid_a} vs {sid_b}\\n'\n",
    "        f'Pearson r = {pair[\"pearson_r\"]:.6f}  —  {sid_b} will be removed',\n",
    "        fontweight='bold'\n",
    "    )\n",
    "    ax.legend(fontsize=9)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step1c-header",
   "metadata": {},
   "source": [
    "### 1c — Applying All Quality-Control Exclusions\n",
    "\n",
    "We now combine every exclusion list from Stages 1a–2 into a final clean cohort, then apply the site-level depth filter (Stage 2.5) to remove low-coverage CpG rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step1c-apply",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Build clean_samples (mirrors pipeline Stages 1a → 2) ──────────────────\n",
    "all_samples    = df_raw['sample_id'].unique().tolist()\n",
    "n_total        = len(all_samples)\n",
    "\n",
    "qc_fail        = [s for s in all_samples if s not in qc_pass]\n",
    "n_qc_failed    = len(qc_fail)\n",
    "n_contaminated = len([s for s in contaminated if s in qc_pass])\n",
    "n_sex_flagged  = len(sex_flagged_ids)\n",
    "n_deduped      = len(dups_to_drop)\n",
    "\n",
    "clean_samples  = [s for s in after_1abc if s not in dups_to_drop]\n",
    "n_clean        = len(clean_samples)\n",
    "\n",
    "df_clean = df_raw[df_raw['sample_id'].isin(clean_samples)].copy()\n",
    "\n",
    "# ── Stage 2.5: site-level depth filter ────────────────────────────────────\n",
    "df_clean, site_stats = filter_site_quality(df_clean, min_depth=5)\n",
    "\n",
    "print('Quality-Control Exclusion Summary')\n",
    "print('=' * 45)\n",
    "print(f'  Input samples              : {n_total}')\n",
    "print(f'  Bisulfite / depth failures : -{n_qc_failed}')\n",
    "print(f'  Contamination flagged      : -{n_contaminated}')\n",
    "print(f'  Sex metadata mixups (XCI)  : -{n_sex_flagged}')\n",
    "print(f'  Technical duplicates       : -{n_deduped}')\n",
    "print(f'  ─────────────────────────────────────────')\n",
    "print(f'  Final clean samples        : {n_clean}')\n",
    "print(f'  Site-level rows removed    : {site_stats[\"n_low\"]:,} ({site_stats[\"pct_low\"]:.1f}% < 5x depth)')\n",
    "print(f'  Rows remaining in df_clean : {len(df_clean):,}')\n",
    "\n",
    "# Exclusion waterfall bar\n",
    "steps  = ['Start', 'Bisulfite\\n/Depth', 'Contamination', 'Sex\\nMixup', 'Duplicate', 'Clean']\n",
    "counts = [n_total,\n",
    "          n_total - n_qc_failed,\n",
    "          n_total - n_qc_failed - n_contaminated,\n",
    "          n_total - n_qc_failed - n_contaminated - n_sex_flagged,\n",
    "          n_clean,\n",
    "          n_clean]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 4))\n",
    "bar_colors = ['#4A90D9'] + ['#F5A623'] * 4 + ['#27AE60']\n",
    "bars = ax.bar(steps, counts, color=bar_colors, alpha=0.85, edgecolor='white', linewidth=0.5)\n",
    "for bar, cnt in zip(bars, counts):\n",
    "    ax.text(bar.get_x() + bar.get_width() / 2, bar.get_height() + 0.3, str(cnt),\n",
    "            ha='center', va='bottom', fontsize=10, fontweight='bold')\n",
    "ax.set_ylabel('Number of samples')\n",
    "ax.set_title('Sample Exclusion Waterfall — All QC Stages', fontweight='bold')\n",
    "ax.set_ylim(0, n_total + 4)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 2: Surgical Strike — Clonal VDJ Masking\n",
    "\n",
    "Some Case samples show extremely high methylation (beta > 0.8) at VDJ recombination loci with unusually long fragment lengths (> 180 bp). This is not a real methylation signal. It is a clonal expansion artifact where a dominant B-cell or T-cell clone has flooded the library with its VDJ-rearranged genome.\n",
    "\n",
    "The correct treatment is surgical: we keep the sample (it contains valid signal elsewhere) but mask the specific VDJ CpGs that are contaminated by the artifact.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2a-header",
   "metadata": {},
   "source": [
    "### 2a — The Problem: A \"Fake Biomarker\" in the VDJ Locus\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2a-vdj-profile",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Capture pre-site-filter snapshot for demo visualization ───────────────\n",
    "# Site filtering removes rows with depth < 5 and could trim\n",
    "# VDJ artifact rows before flag_clonal_artifacts sees them. \n",
    "# To guarantee the artifact is always visible in this walkthrough, \n",
    "# detection and visualization run on the full clean-sample data \n",
    "# BEFORE the depth filter.\n",
    "# The masking in Step 2b still operates on df_clean (site-filtered) which is correct\n",
    "# pipeline behavior. Masking skips rows that were already dropped by the filter.\n",
    "df_pre_site = df_raw[df_raw['sample_id'].isin(clean_samples)].copy()\n",
    "\n",
    "# ── Clonal detection on pre-site-filter data (authoritative for demo) ──────\n",
    "clonal_rows, clonal_samples = flag_clonal_artifacts(df_pre_site)\n",
    "\n",
    "# Cross-check: confirm site filter did not silently hide the artifact\n",
    "_, clonal_post = flag_clonal_artifacts(df_clean)\n",
    "if set(clonal_samples) != set(clonal_post):\n",
    "    print('Note: site filter altered VDJ artifact visibility.')\n",
    "    print(f'  Pre-filter detected : {clonal_samples}')\n",
    "    print(f'  Post-filter detected: {clonal_post}')\n",
    "    print('  Using pre-filter result for demo visualization.')\n",
    "    print('  Step 2b masking is applied to df_clean with this clonal_samples list.')\n",
    "else:\n",
    "    print('Clonal detection is consistent before and after the site depth filter.')\n",
    "\n",
    "print(f'Clonal samples : {clonal_samples}')\n",
    "print(f'Clonal VDJ rows: {len(clonal_rows)}')\n",
    "if len(clonal_rows):\n",
    "    print()\n",
    "    print('Artifact statistics per clonal sample:')\n",
    "    stats = clonal_rows.groupby('sample_id').agg(\n",
    "        n_rows=('beta_value', 'count'),\n",
    "        mean_beta=('beta_value', 'mean'),\n",
    "        mean_frag=('fragment_length', 'mean'),\n",
    "    ).round(3)\n",
    "    display(stats)\n",
    "\n",
    "# ── VDJ profile scatter — pre-site-filter data ensures artifact is visible ─\n",
    "vdj_viz  = df_pre_site[df_pre_site['is_vdj_region']].copy()\n",
    "nvdj_viz = df_pre_site[~df_pre_site['is_vdj_region']].sample(\n",
    "    min(500, len(df_pre_site[~df_pre_site['is_vdj_region']])), random_state=42)\n",
    "\n",
    "vdj_viz['is_clonal'] = vdj_viz['sample_id'].isin(clonal_samples)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(9, 6))\n",
    "\n",
    "ax.scatter(nvdj_viz['fragment_length'], nvdj_viz['beta_value'],\n",
    "           alpha=0.12, s=8, color='#CCCCCC', label='Non-VDJ sites (subsample)', zorder=1)\n",
    "\n",
    "normal_vdj = vdj_viz[~vdj_viz['is_clonal']]\n",
    "ax.scatter(normal_vdj['fragment_length'], normal_vdj['beta_value'],\n",
    "           alpha=0.40, s=18, color='#4A90D9', label='VDJ sites (normal samples)', zorder=2)\n",
    "\n",
    "clonal_vdj = vdj_viz[vdj_viz['is_clonal']]\n",
    "ax.scatter(clonal_vdj['fragment_length'], clonal_vdj['beta_value'],\n",
    "           alpha=0.85, s=55, color='#E05C5C',\n",
    "           label=f'VDJ sites — CLONAL {clonal_samples}', zorder=3)\n",
    "\n",
    "ax.axhline(0.80, color='#8B0000', linestyle='--', linewidth=1.5, alpha=0.85,\n",
    "           label='beta > 0.80 threshold')\n",
    "ax.axvline(180,  color='#8B0000', linestyle=':',  linewidth=1.5, alpha=0.85,\n",
    "           label='frag > 180 bp threshold')\n",
    "x_max = max(int(df_pre_site['fragment_length'].max()), 350)\n",
    "ax.fill_between([180, x_max], 0.80, 1.0, alpha=0.06, color='red')\n",
    "ax.text(185, 0.91, 'Fake-biomarker zone\\nbeta > 0.8  AND  frag > 180 bp',\n",
    "        color='#8B0000', fontsize=8, va='top')\n",
    "\n",
    "ax.set_xlabel('Fragment length (bp)', fontsize=11)\n",
    "ax.set_ylabel('Beta value', fontsize=11)\n",
    "ax.set_title(\n",
    "    'VDJ Clonal Profile — Beta vs Fragment Length\\n'\n",
    "    'The clonal sample occupies the top-right \"fake biomarker\" zone',\n",
    "    fontweight='bold',\n",
    ")\n",
    "ax.legend(fontsize=8)\n",
    "ax.set_xlim(left=50)\n",
    "ax.set_ylim(0, 1)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2b-header",
   "metadata": {},
   "source": [
    "### 2b — The Fix: Flag and Mask the Clonal Signal\n",
    "\n",
    "`mask_clonal_vdj_sites()` sets `beta_value = NaN` only at VDJ-locus rows for clonal samples. Every other CpG from that sample is preserved. This \"surgical\" approach saves the sample's non-VDJ biology while neutralizing the artifact.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2b-mask",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save df_clean snapshot before masking (for the heatmap)\n",
    "df_before_mask = df_clean.copy()\n",
    "\n",
    "# ── Apply VDJ masking (Stage 3.5) ─────────────────────────────────────────\n",
    "if clonal_samples:\n",
    "    df_masked, n_masked = mask_clonal_vdj_sites(df_clean, clonal_samples)\n",
    "    print(f'VDJ sites masked (beta -> NaN) : {n_masked} rows')\n",
    "    print(f'In sample(s)                   : {clonal_samples}')\n",
    "\n",
    "    # Verify: clonal sample VDJ sites now have NaN beta values\n",
    "    clonal_vdj_after = df_masked[\n",
    "        (df_masked['sample_id'].isin(clonal_samples)) &\n",
    "        (df_masked['is_vdj_region'])\n",
    "    ]\n",
    "    pct_nan = clonal_vdj_after['beta_value'].isna().mean() * 100\n",
    "    print(f'Verification: {pct_nan:.1f}% of clonal VDJ rows now have beta_value = NaN')\n",
    "\n",
    "    # Non-VDJ rows for clonal sample are untouched\n",
    "    clonal_nvdj = df_masked[\n",
    "        (df_masked['sample_id'].isin(clonal_samples)) &\n",
    "        (~df_masked['is_vdj_region'])\n",
    "    ]\n",
    "    pct_ok = clonal_nvdj['beta_value'].notna().mean() * 100\n",
    "    print(f'Non-VDJ rows for clonal sample  : {pct_ok:.1f}% intact (no masking applied)')\n",
    "else:\n",
    "    df_masked = df_clean.copy()\n",
    "    n_masked  = 0\n",
    "    print('No clonal samples detected; df_masked = df_clean')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step2c-header",
   "metadata": {},
   "source": [
    "### 2c — The Surgical Heatmap: Before and After\n",
    "\n",
    "The heatmap shows 10 VDJ CpGs × 5 samples (one clonal, four normal). Before masking, the clonal sample shows bright-red high-beta values at these sites — the \"fake biomarker\". After masking, those same cells are `NaN` (shown in gray), and downstream models will impute them to approximately zero (the cohort mean after median centering).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step2c-heatmap",
   "metadata": {},
   "outputs": [],
   "source": [
    "if clonal_samples:\n",
    "    clonal_sid = clonal_samples[0]\n",
    "\n",
    "    # ── Select 10 VDJ CpGs from df_pre_site (full artifact view) ─────────────\n",
    "    # Using pre-site-filter data ensures we always have CpGs to show, even if\n",
    "    # the site depth filter removed borderline-depth VDJ rows from df_clean.\n",
    "    clonal_vdj_cpgs_all = sorted(\n",
    "        df_pre_site[\n",
    "            (df_pre_site['sample_id'] == clonal_sid) &\n",
    "            (df_pre_site['is_vdj_region'])\n",
    "        ]['cpg_id'].unique()\n",
    "    )\n",
    "    heatmap_cpgs = clonal_vdj_cpgs_all[:10]\n",
    "\n",
    "    # Pick 4 normal samples (clean, not clonal)\n",
    "    normal_sids  = sorted([s for s in clean_samples if s not in clonal_samples])[:4]\n",
    "    heatmap_sids = [clonal_sid] + normal_sids\n",
    "\n",
    "    # ── BEFORE pivot: pre-site-filter raw values ───────────────────────────────\n",
    "    # Shows the artifact at full strength — the unmasked, unfiltered inject.\n",
    "    before_pivot = (\n",
    "        df_pre_site[\n",
    "            df_pre_site['cpg_id'].isin(heatmap_cpgs) &\n",
    "            df_pre_site['sample_id'].isin(heatmap_sids)\n",
    "        ]\n",
    "        .pivot(index='cpg_id', columns='sample_id', values='beta_value')\n",
    "        .reindex(columns=heatmap_sids, index=heatmap_cpgs)\n",
    "    )\n",
    "\n",
    "    # ── AFTER pivot: pipeline-masked values ───────────────────────────────────\n",
    "    # df_masked = df_clean (site-filtered) with clonal VDJ rows set to NaN.\n",
    "    # CpGs absent here were removed by site filter before masking.\n",
    "    after_pivot = (\n",
    "        df_masked[\n",
    "            df_masked['cpg_id'].isin(heatmap_cpgs) &\n",
    "            df_masked['sample_id'].isin(heatmap_sids)\n",
    "        ]\n",
    "        .pivot(index='cpg_id', columns='sample_id', values='beta_value')\n",
    "        .reindex(columns=heatmap_sids, index=heatmap_cpgs)\n",
    "    )\n",
    "\n",
    "    # ── Side-by-side heatmaps ──────────────────────────────────────────────────\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    fig.suptitle(\n",
    "        f'Surgical Heatmap — VDJ CpGs: Clonal Sample ({clonal_sid}) vs 4 Normal Samples',\n",
    "        fontsize=12, fontweight='bold',\n",
    "    )\n",
    "\n",
    "    col_labels = [f'{s}\\n(CLONAL)' if s == clonal_sid else s for s in heatmap_sids]\n",
    "\n",
    "    sns.heatmap(before_pivot, ax=axes[0], vmin=0, vmax=1,\n",
    "                cmap='RdYlBu_r', annot=True, fmt='.2f', linewidths=0.5,\n",
    "                cbar_kws={'label': 'Beta value'},\n",
    "                xticklabels=col_labels)\n",
    "    axes[0].set_title(\n",
    "        'BEFORE Masking  (raw, pre-site-filter)\\nClonal column: inflated beta 0.8–1.0',\n",
    "        fontweight='bold')\n",
    "    axes[0].set_ylabel('CpG site')\n",
    "    axes[0].tick_params(axis='x', labelsize=8)\n",
    "\n",
    "    sns.heatmap(after_pivot, ax=axes[1], vmin=0, vmax=1,\n",
    "                cmap='RdYlBu_r', annot=True, fmt='.2f', linewidths=0.5,\n",
    "                cbar_kws={'label': 'Beta value'},\n",
    "                xticklabels=col_labels)\n",
    "    # Annotate cells that are NaN in the after pivot\n",
    "    for cpg_idx, cpg in enumerate(heatmap_cpgs):\n",
    "        for sid_idx, sid in enumerate(heatmap_sids):\n",
    "            val = after_pivot.loc[cpg, sid] if cpg in after_pivot.index else float('nan')\n",
    "            if pd.isna(val):\n",
    "                label = 'NaN\\n(masked)' if cpg in before_pivot.index and not pd.isna(before_pivot.loc[cpg, sid]) else 'N/A\\n(filtered)'\n",
    "                axes[1].text(sid_idx + 0.5, cpg_idx + 0.5, label,\n",
    "                             ha='center', va='center', fontsize=7,\n",
    "                             color='black', fontweight='bold')\n",
    "\n",
    "    axes[1].set_title(\n",
    "        'AFTER Masking  (site-filtered + masked)\\nClonal VDJ cells -> NaN -> imputed ~0',\n",
    "        fontweight='bold')\n",
    "    axes[1].set_ylabel('')\n",
    "    axes[1].tick_params(axis='x', labelsize=8)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    print()\n",
    "    print('Result: The clonal sample is RETAINED in the cohort.')\n",
    "    print('Only its VDJ CpG rows are neutralized. All other signal is preserved.')\n",
    "    print('Downstream models (DMR hunter, ML guard) impute the NaN rows to ~0.')\n",
    "else:\n",
    "    print('No clonal samples detected; heatmap skipped.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step3-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 3: Harmonization — Batch Normalization\n",
    "\n",
    "Even after removing all bad samples, we showed in Step 0 that `Batch_01` is enriched for Case samples (Cramér's V > 0.5). The `normalizer` module checks for this confound and applies median centering — a method that preserves relative CpG-to-CpG differences within a sample while removing the batch-driven offset.\n",
    "\n",
    "> Why not quantile normalization? It distorts the bimodal shape of methylation distributions, which is a biologically meaningful feature. Median centering does not.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step3-normalize",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "After median centering, the dominant batch-driven principal component is removed.\n",
      "Variance now reflects biological signal (disease label) rather than technical noise.\n"
     ]
    }
   ],
   "source": [
    "# ── Stage 4: Confound checks ────────────────────────────────────────────────\n",
    "batch_confound = check_confounding(df_masked, 'batch_id', 'disease_label')\n",
    "sex_confound   = check_confounding(df_masked, 'sex',      'disease_label')\n",
    "age_confound   = check_continuous_confound(df_masked, 'age', 'disease_label')\n",
    "\n",
    "print('Confound Check Results')\n",
    "print('=' * 55)\n",
    "print(f\"  Batch × Disease  Cramér's V = {batch_confound['cramers_v']:.4f}  \"\n",
    "      f\"p = {batch_confound['p_value']:.2e}  \"\n",
    "      f\"{'CONFOUNDED' if batch_confound['confounded'] else 'OK'}\")\n",
    "print(f\"  Sex × Disease    Cramér's V = {sex_confound['cramers_v']:.4f}  \"\n",
    "      f\"p = {sex_confound['p_value']:.2e}  \"\n",
    "      f\"{'CONFOUNDED' if sex_confound['confounded'] else 'balanced'}\")\n",
    "print(f\"  Age × Disease    F = {age_confound['f_stat']:.4f}  \"\n",
    "      f\"p = {age_confound['p_value']:.4f}  \"\n",
    "      f\"{'CONFOUNDED' if age_confound['confounded'] else 'balanced'}\")\n",
    "print()\n",
    "print('Contingency table (batch x disease):')\n",
    "display(batch_confound['contingency_table'])\n",
    "print()\n",
    "print('Interpretation:')\n",
    "print('  Batch × Disease is strongly confounded (Cramér V > 0.5) — normalization is required.')\n",
    "print('  Sex and age are balanced between groups — they are NOT confounders,')\n",
    "print('  but including them as OLS covariates (Stage 6) still improves power')\n",
    "print('  by accounting for their independent methylation effects.')\n",
    "\n",
    "# ── Stage 4: Normalize ────────────────────────────────────────────────────\n",
    "df_norm = robust_normalize(df_masked, save_figure=False)\n",
    "\n",
    "print()\n",
    "print(f\"Normalization complete.  'beta_normalized' column added.\")\n",
    "print(f\"Columns now: {list(df_norm.columns)}\")\n",
    "\n",
    "# ── Before / After PCA ────────────────────────────────────────────────────\n",
    "pca_before, var_before = compute_pca_coords(df_masked, value_col='beta_value')\n",
    "pca_after,  var_after  = compute_pca_coords(df_norm,   value_col='beta_normalized')\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('Normalization Effect — Before vs After PCA', fontsize=13, fontweight='bold')\n",
    "\n",
    "# ── Left: Before normalization, colored by batch ───────────────────────────\n",
    "ax = axes[0]\n",
    "for batch, grp in pca_before.groupby('batch_id'):\n",
    "    ax.scatter(grp['PC1'], grp['PC2'], label=batch,\n",
    "               color=BATCH_PAL.get(batch, 'gray'), alpha=0.85, s=70, edgecolors='white', linewidths=0.5)\n",
    "ax.set_xlabel(f'PC1 ({var_before[0]:.1%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({var_before[1]:.1%} variance)')\n",
    "ax.set_title('BEFORE Normalization\\nColored by Batch (problem visible)', fontweight='bold')\n",
    "ax.legend(title='Batch', fontsize=9)\n",
    "\n",
    "# ── Right: After normalization, colored by disease ─────────────────────────\n",
    "ax = axes[1]\n",
    "for disease, grp in pca_after.groupby('disease_label'):\n",
    "    ax.scatter(grp['PC1'], grp['PC2'], label=disease,\n",
    "               color=DISEASE_PAL.get(disease, 'gray'), alpha=0.85, s=70, edgecolors='white', linewidths=0.5)\n",
    "ax.set_xlabel(f'PC1 ({var_after[0]:.1%} variance)')\n",
    "ax.set_ylabel(f'PC2 ({var_after[1]:.1%} variance)')\n",
    "ax.set_title('AFTER Normalization\\nColored by Disease (batch clusters dissolved)', fontweight='bold')\n",
    "ax.legend(title='Disease', fontsize=9)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('After median centering, the dominant batch-driven principal component is removed.')\n",
    "print('Variance now reflects biological signal (disease label) rather than technical noise.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kfmzrgh8bb",
   "metadata": {},
   "source": [
    "---\n",
    "### Visual 4 — Covariate Structure: Batch, Disease Label, Sex, Age\n",
    "\n",
    "PC1 separates Batch_01 Cases from everyone else — driven by the batch confound and the true biological DMR signal acting together. PC2 separates males from females within the Batch_01 Case cluster, with zero overlap (mean PC2: F = +0.79, M = −0.69).\n",
    "\n",
    "This confirms that both sex and age must be included as covariates in any linear model applied to this cohort. A naive Wilcoxon test comparing Cases vs. Controls without adjusting for sex risks flagging sex-dimorphic autosomal CpGs as disease signal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30u89lzgnko",
   "metadata": {},
   "outputs": [],
   "source": [
    "from core.infrastructure.visuals import plot_pca_covariates\n",
    "from IPython.display import Image\n",
    "\n",
    "cov_path = plot_pca_covariates(df_norm)\n",
    "Image(cov_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step4-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 4: Scientific Discovery — Differentially Methylated Regions\n",
    "\n",
    "With a clean, normalized dataset, we run `dmr_hunter`: a distance-based CpG cluster caller that groups nearby CpGs (within 1000 bp, ≥ 3 CpGs per cluster) and tests each cluster for Case vs. Control methylation differences.\n",
    "\n",
    "**Statistical model**: when `covariate_cols` are provided (here `[\"age\", \"sex\"]`), an OLS linear model is fit per cluster using logit-transformed M-values:\n",
    "\n",
    "```\n",
    "M-value ~ disease_label + age + C(sex)\n",
    "```\n",
    "\n",
    "The `disease_label` coefficient t-statistic drives the p-value; `delta_beta` is reported on the raw beta scale for biological interpretability.  When no covariates are passed the test falls back to Wilcoxon rank-sum (backward-compatible).\n",
    "\n",
    "Clusters passing both **p_adj < 0.05** and **|ΔBeta| > 0.10** (BH-corrected) are called significant.\n",
    "\n",
    "**Positive control**: CpGs `cg00003000`–`cg00003010` (11 CpGs, chr6:30 Mb) were injected with a +0.25 Case shift at data-generation time — this cluster should be the top DMR hit.\n",
    "\n",
    "**Negative controls**: Two sub-threshold signals were also injected to confirm the caller does not over-call:\n",
    "- *Borderline* — `cg00001500`–`cg00001507` (8 CpGs, raw +0.09 shift): expected post-normalization ΔBeta ≈ +0.08, **below threshold**.\n",
    "- *Subtle* — `cg00002000`–`cg00002005` (6 CpGs, raw +0.08 shift): expected ΔBeta ≈ +0.04, **well below threshold**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step4-dmr",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Stage 6: DMR Hunter (OLS with age + sex covariates) ────────────────────\n",
    "dmrs = find_dmrs(\n",
    "    df_norm, clean_samples,\n",
    "    normalized_col='beta_normalized',\n",
    "    covariate_cols=['age', 'sex'],\n",
    ")\n",
    "\n",
    "sig_dmrs    = dmrs[dmrs['significant']]\n",
    "clonal_dmrs = dmrs[dmrs['clonal_risk']]\n",
    "sig_clonal  = sig_dmrs[sig_dmrs['clonal_risk']]\n",
    "\n",
    "print(f'Total clusters tested    : {len(dmrs):,}')\n",
    "print(f'Test method used         : {dmrs[\"test_method\"].unique()}')\n",
    "print(f'Significant DMRs (p_adj < 0.05, |ΔBeta| > 0.10) : {len(sig_dmrs)}')\n",
    "print(f'Clusters overlapping VDJ loci (clonal_risk=True)  : {len(clonal_dmrs)}')\n",
    "print(f'Significant DMRs with clonal risk                 : {len(sig_clonal)}')\n",
    "print()\n",
    "print('Significant DMRs:')\n",
    "display(sig_dmrs[['window_id', 'chrom', 'start_pos', 'n_cpgs', 'case_mean', 'ctrl_mean',\n",
    "                   'delta_beta', 'test_stat', 'p_adj', 'n_vdj_cpgs', 'clonal_risk', 'mean_gc']]\n",
    "        .sort_values('p_adj')\n",
    "        .style.background_gradient(subset=['delta_beta'], cmap='RdBu_r')\n",
    "        .format({'case_mean': '{:.3f}', 'ctrl_mean': '{:.3f}',\n",
    "                 'delta_beta': '{:+.3f}', 'test_stat': '{:.2f}',\n",
    "                 'p_adj': '{:.2e}', 'mean_gc': '{:.2f}'}))\n",
    "\n",
    "# ── Negative-control verification ─────────────────────────────────────────\n",
    "# CpGs known to carry sub-threshold injected shifts should NOT appear as\n",
    "# significant DMRs — confirming the caller does not over-call near the boundary.\n",
    "borderline_cpgs = {f'cg{i:08d}' for i in range(1500, 1508)}\n",
    "subtle_cpgs     = {f'cg{i:08d}' for i in range(2000, 2006)}\n",
    "\n",
    "def _cluster_contains(row, cpg_set):\n",
    "    return bool(set(str(row['cpgs']).split(',')) & cpg_set)\n",
    "\n",
    "borderline_clusters = dmrs[dmrs['cpgs'].apply(lambda c: bool({f'cg{i:08d}' for i in range(1500, 1508)} & set(str(c).split(','))))]\n",
    "subtle_clusters     = dmrs[dmrs['cpgs'].apply(lambda c: bool({f'cg{i:08d}' for i in range(2000, 2006)} & set(str(c).split(','))))]\n",
    "\n",
    "print()\n",
    "print('Negative-control verification')\n",
    "print('-' * 45)\n",
    "for label, subset in [('Borderline (cg1500-1507, +0.09 raw shift)', borderline_clusters),\n",
    "                      ('Subtle     (cg2000-2005, +0.08 raw shift)', subtle_clusters)]:\n",
    "    if len(subset):\n",
    "        row = subset.iloc[0]\n",
    "        status = 'PASS (not significant)' if not row['significant'] else 'FAIL — false positive!'\n",
    "        print(f'  {label}')\n",
    "        print(f'    cluster={row[\"window_id\"]}  ΔBeta={row[\"delta_beta\"]:+.3f}  '\n",
    "              f'p_adj={row[\"p_adj\"]:.2e}  significant={row[\"significant\"]}  -> {status}')\n",
    "    else:\n",
    "        print(f'  {label}: cluster not detected (CpGs too sparse for clustering)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step4-volcano",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ── Volcano plot with highlighted signal and VDJ annotation ───────────────\n",
    "fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "fig.suptitle('DMR Volcano Plots — From Noise to Signal', fontsize=13, fontweight='bold')\n",
    "\n",
    "for ax_idx, (ax, title_suffix) in enumerate(zip(axes, ['Standard', 'Annotated: VDJ windows in orange'])):\n",
    "\n",
    "    # All non-significant windows\n",
    "    ns = dmrs[~dmrs['significant'] & ~dmrs['clonal_risk']]\n",
    "    ax.scatter(ns['delta_beta'], -np.log10(ns['p_adj'] + 1e-10),\n",
    "               alpha=0.25, s=10, color='#AAAAAA', label='Not significant')\n",
    "\n",
    "    if ax_idx == 1:\n",
    "        # VDJ / clonal-risk windows in orange\n",
    "        cr = dmrs[dmrs['clonal_risk'] & ~dmrs['significant']]\n",
    "        ax.scatter(cr['delta_beta'], -np.log10(cr['p_adj'] + 1e-10),\n",
    "                   alpha=0.6, s=30, color='#F5A623', label='VDJ clonal-risk window', zorder=3)\n",
    "        cr_sig = dmrs[dmrs['clonal_risk'] & dmrs['significant']]\n",
    "        if len(cr_sig):\n",
    "            ax.scatter(cr_sig['delta_beta'], -np.log10(cr_sig['p_adj'] + 1e-10),\n",
    "                       alpha=0.9, s=60, color='#F5A623', edgecolors='black', linewidths=0.8,\n",
    "                       label='VDJ sig. DMR (treat with caution)', zorder=4)\n",
    "\n",
    "    # Non-VDJ significant windows\n",
    "    sig_nonvdj = sig_dmrs[~sig_dmrs['clonal_risk']]\n",
    "    ax.scatter(sig_nonvdj['delta_beta'], -np.log10(sig_nonvdj['p_adj'] + 1e-10),\n",
    "               alpha=0.9, s=80, color='#E05C5C', edgecolors='black', linewidths=0.8,\n",
    "               label='Significant DMR (true biology)', zorder=5)\n",
    "\n",
    "    # Annotate significant DMRs\n",
    "    for _, row in sig_dmrs.iterrows():\n",
    "        ax.annotate(\n",
    "            f\"{row['window_id']}\\ndBeta={row['delta_beta']:+.2f}\",\n",
    "            (row['delta_beta'], -np.log10(row['p_adj'] + 1e-10)),\n",
    "            textcoords='offset points', xytext=(6, 4),\n",
    "            fontsize=7, color='#8B0000', fontweight='bold'\n",
    "        )\n",
    "\n",
    "    # Threshold lines\n",
    "    ax.axhline(-np.log10(0.05), color='gray', linestyle='--', linewidth=0.9, label='p_adj = 0.05')\n",
    "    ax.axvline( 0.10, color='gray', linestyle=':', linewidth=0.9)\n",
    "    ax.axvline(-0.10, color='gray', linestyle=':', linewidth=0.9)\n",
    "\n",
    "    ax.set_xlabel('Delta Beta (Case - Control)', fontsize=11)\n",
    "    ax.set_ylabel('-log10(p_adj)', fontsize=11)\n",
    "    ax.set_title(title_suffix, fontweight='bold')\n",
    "    ax.legend(fontsize=7, loc='upper left')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "if len(sig_dmrs):\n",
    "    top = sig_dmrs.sort_values('p_adj').iloc[0]\n",
    "    print(f'Top hit: {top[\"window_id\"]}  '\n",
    "          f'dBeta={top[\"delta_beta\"]:+.3f}  '\n",
    "          f'p_adj={top[\"p_adj\"]:.2e}  '\n",
    "          f'clonal_risk={top[\"clonal_risk\"]}')\n",
    "    if not top['clonal_risk']:\n",
    "        print('The top DMR carries NO clonal risk flag — it reflects true biology, not VDJ artifact.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "step5-header",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 5: Machine Learning Validation — ML Guard\n",
    "\n",
    "The final validation step asks: can the cleaned signal actually discriminate Case from Control? We use an ElasticNet logistic classifier with `GroupKFold` cross-validation — leakage-proof because samples from the same patient never appear in both train and test folds.\n",
    "\n",
    "The key narrative: Without VDJ masking, a model could exploit the clonal methylation artifact to achieve an artificially inflated AUC. By masking those sites _before_ the model ever sees them, the AUC reflects only genuine disease-associated CpGs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "step5-ml",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Interpretation:\n",
      "  AUC = 1.0000: The injected biological signal (11 CpGs, +0.25 dBeta) is\n",
      "  strong enough for near-perfect separation in this mock dataset.\n",
      "  In real clinical data with a weaker signal-to-noise ratio, an honest\n",
      "  AUC of 0.70-0.90 is typical after proper artifact removal.\n",
      "\n",
      "Key guarantee: GroupKFold ensures no patient appears in both train and test.\n",
      "The AUC cannot be inflated by sample-level data leakage.\n"
     ]
    }
   ],
   "source": [
    "# ── Stage 7: ML Guard ─────────────────────────────────────────────────────\n",
    "print('Running ElasticNet + GroupKFold CV on the cleaned, normalized data...')\n",
    "ml_result = run_safe_model(df_norm, feature_col='beta_normalized')\n",
    "\n",
    "print()\n",
    "print('ML Guard Results')\n",
    "print('=' * 45)\n",
    "print(f\"  Mean AUC         : {ml_result['mean_auc']:.4f} +/- {ml_result['std_auc']:.4f}\")\n",
    "print(f\"  Mean Accuracy    : {ml_result['mean_accuracy']:.4f}\")\n",
    "print(f\"  n_samples        : {ml_result['n_samples']}\")\n",
    "print(f\"  n_features (CpGs): {ml_result['n_features']}\")\n",
    "if ml_result.get('warning'):\n",
    "    print(f\"  Warning          : {ml_result['warning']}\")\n",
    "\n",
    "print()\n",
    "print('Cross-validation fold detail:')\n",
    "for fold_key, fold_val in ml_result['cv_results'].items():\n",
    "    print(f'  {fold_key}: {fold_val}')\n",
    "\n",
    "# ── AUC bar chart with narrative ───────────────────────────────────────────\n",
    "fig, ax = plt.subplots(figsize=(8, 5))\n",
    "\n",
    "auc_val  = ml_result['mean_auc']\n",
    "auc_std  = ml_result['std_auc']\n",
    "bar_col  = '#27AE60' if auc_val >= 0.70 else '#E05C5C'\n",
    "\n",
    "ax.barh(['Honest AUC\\n(VDJ masked)'], [auc_val], color=bar_col, alpha=0.85, height=0.35,\n",
    "        xerr=[auc_std], error_kw={'elinewidth': 2, 'capsize': 6, 'capthick': 2, 'ecolor': 'black'})\n",
    "ax.axvline(0.5,  color='red',  linestyle='--', linewidth=1.2, label='Random classifier (0.50)')\n",
    "ax.axvline(0.70, color='gray', linestyle=':',  linewidth=1.0, label='Clinical relevance threshold (0.70)')\n",
    "ax.text(auc_val + auc_std + 0.01, 0, f'{auc_val:.4f}', va='center', fontsize=11, fontweight='bold', color=bar_col)\n",
    "\n",
    "ax.set_xlim(0, 1.1)\n",
    "ax.set_xlabel('ROC-AUC', fontsize=11)\n",
    "ax.set_title(\n",
    "    'ElasticNet + GroupKFold CV — Classification AUC\\n'\n",
    "    'VDJ clonal sites are masked; AUC reflects genuine disease signal',\n",
    "    fontweight='bold'\n",
    ")\n",
    "ax.legend(fontsize=9)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print()\n",
    "print('Interpretation:')\n",
    "if auc_val >= 0.95:\n",
    "    print(f'  AUC = {auc_val:.4f}: The injected biological signal (11 CpGs, +0.25 dBeta) is')\n",
    "    print('  strong enough for near-perfect separation in this mock dataset.')\n",
    "    print('  In real clinical data with a weaker signal-to-noise ratio, an honest')\n",
    "    print('  AUC of 0.70-0.90 is typical after proper artifact removal.')\n",
    "print()\n",
    "print('Key guarantee: GroupKFold ensures no patient appears in both train and test.')\n",
    "print('The AUC cannot be inflated by sample-level data leakage.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "summary",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary: From Noise to Signal\n",
    "\n",
    "This notebook walked through a complete, rigorous artifact-removal pipeline applied to simulated B-cell/T-cell DNA methylation data with 100 patients (50 Case, 50 Control) across 10,000 CpGs.\n",
    "\n",
    "| Stage | Action | Samples / Rows Removed |\n",
    "|-------|--------|------------------------|\n",
    "| 1a: Bisulfite QC | Non-CpG rate > 2% or mean depth < 10x | 3 samples |\n",
    "| 1b: Contamination | Bimodal beta distribution (S020) | 1 sample |\n",
    "| 1c: XCI Guard | X-linked beta contradicts reported sex | 2 samples |\n",
    "| 2: Deduplication | Pearson r > 0.99 (S010 ↔ S_DUP) | 1 sample |\n",
    "| 2.5: Site Filter | CpG rows with depth < 5x | ~0.9% of rows |\n",
    "| 3: Clonal Masking | VDJ beta > 0.8 AND fragment > 180 bp | NaN at VDJ rows only |\n",
    "| 4: Normalization | Median centering per sample | (batch offset removed) |\n",
    "| 4: Confound check | Batch × Disease (Cramér V > 0.5) detected | (informational) |\n",
    "| 4: Covariate check | Sex and age are balanced | (used as OLS covariates) |\n",
    "| 6: DMR Hunter | OLS per cluster with age + sex covariates | — |\n",
    "\n",
    "**Final result**: 101 → 94 clean samples. The injected true biological DMR (`cg00003000`–`cg00003010`, chr6:30 Mb, ΔBeta ≈ +0.18) is recovered as the top significant hit. The two sub-threshold negative-control clusters (borderline ΔBeta ≈ 0.08, subtle ΔBeta ≈ 0.04) are correctly not called significant — confirming the pipeline does not over-call at the detection boundary. AUC reflects genuine disease-associated methylation.\n",
    "\n",
    "---\n",
    "\n",
    "> Every detection threshold, statistical test, and correction method demonstrated in this notebook lives in `core/`. The notebook itself is a display layer only — reproducible by re-running all cells from top to bottom.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cci9gppbydh",
   "metadata": {},
   "source": [
    "---\n",
    "## Step 6: Generate the PDF Report\n",
    "\n",
    "The pipeline includes an 8-section PDF report that bundles the audit log, all QC figures, the DMR table, and the ML AUC into a single shareable document. Running it here regenerates the full pipeline end-to-end (fast — the mock data is small) and writes the PDF to `output/`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rf2acerezp",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import glob\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath('..')\n",
    "\n",
    "result = subprocess.run(\n",
    "    ['python', 'core/orchestration/pipeline.py', '--report'],\n",
    "    cwd=project_root,\n",
    "    capture_output=True,\n",
    "    text=True,\n",
    ")\n",
    "\n",
    "# Find the most-recently written report\n",
    "reports = sorted(glob.glob(os.path.join(project_root, 'output', 'report_*.pdf')))\n",
    "if reports:\n",
    "    latest = reports[-1]\n",
    "    size_kb = os.path.getsize(latest) / 1024\n",
    "    print(f'Report written: {os.path.relpath(latest, project_root)}  ({size_kb:.0f} KB)')\n",
    "else:\n",
    "    print('Report not found — see stderr below.')\n",
    "\n",
    "if result.returncode != 0:\n",
    "    print('\\nSTDERR:')\n",
    "    print(result.stderr[-2000:])  # last 2000 chars to avoid flooding the notebook\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
